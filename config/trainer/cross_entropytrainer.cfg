[trainer]
#name of the trainer that should be used
trainer = cross_entropy
#if set to True training will resume from latest checkpoint
resume_training = False
#number of passes over the entire database
num_epochs = 100
#initial learning rate of the neural net
initial_learning_rate = 1e-3
#exponential weight decay parameter
learning_rate_decay = 1
#size of the minibatch (#utterances)
batch_size = 2
#number of minibatches to aggregate before updating the parameters if 0
#asstnchronous training will be done
numbatches_to_aggregate = 0
#if there is no dev set a dev set will be created from the training set, this
#sets the number of training utterances that will be used for validation
valid_utt = 16
#The validation mode, options are decode and loss. Decode will decode the
#validation set and compare with the validation targets. Loss will compute the
#loss on the validation set
validation_mode = decode
#frequency of evaluating the validation set. CATION: If the valid_frequency is
#more than 5 times larger than the checkpoint frequency the validated model
#will be deleted by the saver
valid_frequency = 500
#if you want to adapt the learning rate based on the validation set, set to True
valid_adapt = True
